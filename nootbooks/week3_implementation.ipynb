{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMtdVC5nOU4IfsU/4JNn9GL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lexaun-chen/STAT-4830-Group-Project/blob/main/nootbooks/week3_implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Classes"
      ],
      "metadata": {
        "id": "-oso_dzoitYh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50MGtJmTy_Bl"
      },
      "outputs": [],
      "source": [
        "class DiagonalLinear(nn.Module):\n",
        "    def __init__(self, size):\n",
        "        super(DiagonalLinear, self).__init__()\n",
        "        self.size = size\n",
        "        self.diag = nn.Parameter(torch.ones(size))  # Initialize diagonal entries as ones\n",
        "    def forward(self, x):\n",
        "        # Construct diagonal matrix\n",
        "        diag_matrix = torch.diag(self.diag)\n",
        "        return x @ diag_matrix\n",
        "\n",
        "\n",
        "class MNL(nn.Module):\n",
        "    def __init__(self, OptSize):\n",
        "        super().__init__()\n",
        "        self.input_linear = DiagonalLinear(OptSize)\n",
        "\n",
        "    def forward(self, e):\n",
        "        mask = e == 1\n",
        "        e = self.input_linear(e)\n",
        "        masked_e = torch.where(mask == 1, e, float('-inf'))\n",
        "        masked_softmax_e = F.softmax(masked_e, dim=-1)\n",
        "        return masked_softmax_e, e"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Application Instance"
      ],
      "metadata": {
        "id": "KLFXL9FXi9u2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Synthetic Hypothetical Data\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import itertools\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def generate_one_hot(probabilities):\n",
        "    probabilities = np.array(probabilities)\n",
        "    p_index = np.random.choice(len(probabilities), p=probabilities)\n",
        "    one_hot = np.zeros_like(probabilities)\n",
        "    one_hot[p_index] = 1\n",
        "    return one_hot\n",
        "\n",
        "\n",
        "product_set = [0, 1, 2, 3]\n",
        "offer_set = [0, 1, 2, 3]\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "\n",
        "hypothetical_choice_p = [[0.98, 0.02, 0, 0],\n",
        "                         [0.5, 0, 0.5, 0],\n",
        "                         [0.5, 0, 0, 0.5],\n",
        "                         [0, 0.5, 0.5, 0],\n",
        "                         [0, 0.5, 0, 0.5],\n",
        "                         [0, 0, 0.9, 0.1],\n",
        "                         [0.49, 0.01, 0.5, 0],\n",
        "                         [0.49, 0.01, 0, 0.5],\n",
        "                         [0.5, 0, 0.45, 0.05],\n",
        "                         [0, 0.5, 0.45, 0.05],\n",
        "                         [0.49, 0.01, 0.45, 0.05]]\n",
        "\n",
        "index = 0\n",
        "for r in range(2, len(offer_set) + 1):\n",
        "    for subset in itertools.combinations(offer_set, r):\n",
        "        binary_subset = [1 if x in subset else 0 for x in offer_set]\n",
        "        p = hypothetical_choice_p[index]\n",
        "        for _ in range(200):\n",
        "            X.append(binary_subset)\n",
        "            Y.append(generate_one_hot(p).reshape((1, len(product_set))))\n",
        "        index += 1\n",
        "\n",
        "\n",
        "np.random.seed(10)\n",
        "X = np.array(X)\n",
        "Y = np.concatenate(Y, axis=0)\n",
        "dataset = np.concatenate((X, Y), axis=1)\n",
        "df = pd.DataFrame(dataset, columns=['X' + str(i) for i in product_set] + ['Y' + str(i) for i in product_set])\n",
        "csv_file = 'hypothetical-4p-test.csv'\n",
        "df.to_csv(csv_file, index=False)\n",
        "\n",
        "\n",
        "X = []\n",
        "Y = []\n",
        "np.random.seed(42)\n",
        "index = 0\n",
        "for r in range(2, len(offer_set) + 1):\n",
        "    for subset in itertools.combinations(offer_set, r):\n",
        "        binary_subset = [1 if x in subset else 0 for x in offer_set]\n",
        "        p = hypothetical_choice_p[index]\n",
        "        for _ in range(2000):\n",
        "            X.append(binary_subset)\n",
        "            Y.append(generate_one_hot(p).reshape((1, len(product_set))))\n",
        "        index += 1\n",
        "\n",
        "\n",
        "X = np.array(X)\n",
        "Y = np.concatenate(Y, axis=0)\n",
        "dataset = np.concatenate((X, Y), axis=1)\n",
        "df = pd.DataFrame(dataset, columns=['X' + str(i) for i in product_set] + ['Y' + str(i) for i in product_set])\n",
        "csv_file = 'hypothetical-4p-train.csv'\n",
        "df.to_csv(csv_file, index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "3Tp2uTV6GmVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Train Test MNL\n",
        "\"\"\"\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def calc_freq(X, Y):\n",
        "    X = X.float()\n",
        "    Y = Y.float()\n",
        "    unique_X, inverse_indices = torch.unique(X, dim=0, return_inverse=True)\n",
        "    new_Y = torch.zeros_like(Y)\n",
        "    print(unique_X)\n",
        "    for k in range(unique_X.shape[0]):\n",
        "        mask = (inverse_indices == k)\n",
        "        avg_y = torch.mean(Y[mask], dim=0)\n",
        "        new_Y[mask] = avg_y\n",
        "        print(avg_y)\n",
        "    return new_Y\n",
        "\n",
        "\n",
        "class DiagonalLinear(nn.Module):\n",
        "    def __init__(self, size):\n",
        "        super(DiagonalLinear, self).__init__()\n",
        "        self.size = size\n",
        "        self.diag = nn.Parameter(torch.ones(size))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 创建对角矩阵\n",
        "        diag_matrix = torch.diag(self.diag)\n",
        "        return x @ diag_matrix\n",
        "\n",
        "\n",
        "class MNL(nn.Module):\n",
        "    def __init__(self, OptSize):\n",
        "        super().__init__()\n",
        "        self.input_linear = DiagonalLinear(OptSize)\n",
        "\n",
        "    def forward(self, e):\n",
        "        mask = e == 1\n",
        "        e = self.input_linear(e)\n",
        "        masked_e = torch.where(mask == 1, e, float('-inf'))\n",
        "        masked_softmax_e = F.softmax(masked_e, dim=-1)\n",
        "        return masked_softmax_e, e\n",
        "\n",
        "\n",
        "def log_likelihood(out, y, safe_log=0):\n",
        "    ones_indices = y == 1\n",
        "    probabilities = out[ones_indices]\n",
        "    negative_log_probabilities = -torch.log(probabilities + safe_log)\n",
        "    total_negative_log_prob = torch.sum(negative_log_probabilities)\n",
        "    return total_negative_log_prob / y.shape[0]\n",
        "\n",
        "\n",
        "def train_synthetic(loss_name, num_epochs):\n",
        "    input_dim = 4\n",
        "    main_network = MNL(input_dim)\n",
        "    train_file_path = 'hypothetical-4p-train.csv'\n",
        "    test_file_path = 'hypothetical-4p-test.csv'\n",
        "    df_train = pd.read_csv(train_file_path)\n",
        "    df_test = pd.read_csv(test_file_path)\n",
        "    X_columns = [col for col in df_train.columns if col.startswith('X')]\n",
        "    Y_columns = [col for col in df_train.columns if col.startswith('Y')]\n",
        "    X_train = torch.tensor(df_train[X_columns].values, dtype=torch.float)\n",
        "    Y_train = torch.tensor(df_train[Y_columns].values, dtype=torch.float)\n",
        "    Y_train_freq = calc_freq(X_train, Y_train)\n",
        "    X_test = torch.tensor(df_test[X_columns].values, dtype=torch.float)\n",
        "    Y_test = torch.tensor(df_test[Y_columns].values, dtype=torch.float)\n",
        "    Y_test_freq = calc_freq(X_test, Y_test)\n",
        "    optimizer = Adam(main_network.parameters(), lr=0.01, weight_decay=0)\n",
        "\n",
        "    in_loss = None\n",
        "    if loss_name == 'NLL':\n",
        "        L = log_likelihood\n",
        "    else:\n",
        "        L = nn.MSELoss()\n",
        "    for epoch in range(num_epochs):\n",
        "        output, _ = main_network(X_train)\n",
        "        loss = L(output, Y_train)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        in_loss = loss.item()\n",
        "        with torch.no_grad():\n",
        "            freq_loss = L(output, Y_train_freq)\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(f'Epoch [{epoch + 1}/{num_epochs}], Original Loss: {loss.item() ** 0.5:.4f},'\n",
        "                  f' Frequency Loss: {freq_loss.item() ** 0.5:.8f}')\n",
        "    final_output, _ = main_network(X_test)\n",
        "    torch.save(main_network, 'MNL_Model-hyp.pth')\n",
        "    return in_loss ** 0.5, freq_loss.item() ** 0.5,\\\n",
        "        L(final_output, Y_test).item() ** 0.5, L(final_output, Y_test_freq).item() ** 0.5\n",
        "\n",
        "\n",
        "Loss_Name = 'MSE'\n",
        "epochs = 2000\n",
        "in_sample_RMSE, in_sample_RMSE_Freq, out_sample_RMSE, out_sample_RMSE_Freq = train_synthetic(Loss_Name, epochs)\n",
        "print('in_sample_RMSE, in_sample_RMSE_Freq, out_sample_RMSE, out_sample_RMSE_Freq')\n",
        "print(in_sample_RMSE,  in_sample_RMSE_Freq, out_sample_RMSE, out_sample_RMSE_Freq)"
      ],
      "metadata": {
        "id": "FxVC9O9iGty5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}